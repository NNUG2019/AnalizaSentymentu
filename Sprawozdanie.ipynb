{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sprawozdanie.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8_0C2Qz0B4T",
        "colab_type": "text"
      },
      "source": [
        "#Sprawozdanie z laboratorium - sieci neuronowe\n",
        "\n",
        "**Temat:** Analiza sentymentu\n",
        "\n",
        "**Skład grupy:** \n",
        "\n",
        "Aleksandra Rykaczewska, Marika Jońca, Klaudia Biernat\n",
        "\n",
        "**Opis zadania:**\n",
        "\n",
        "- Naszym zadaniem jest przeanalizowanie otrzymanych danych, stworzenie modelu uczącego sieć oraz analiza stworzonego modelu. Sieć ta ma określać sentyment, negatywny bądź pozytywny, danego tekstu korzystając z recenzji filmów z IMDB. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqS_dbD1Hj6U",
        "colab_type": "text"
      },
      "source": [
        "#Dane\n",
        "\n",
        "Zestaw danych, z którego będziemy korzystać pochodzi z biblioteki `tensorflow_dataset`.  Jest to ogólnodostępna biblioteka, która umożliwia nam dostęp do różnych zbiorów danych. Do analizy sentymentu będziemy posługiwać się danymi ze zbioru `imbd_reviews` zawierającego 8000 subsłów.\n",
        "\n",
        "Baza ta składa się z 100 000 rekordów, zawierajacych po 25000 recenzji zbioru treningowego i zbioru uczącego oraz 50000 recenzji o nieokreślonym sentymencie, które można wykorzystać do trenowania sieci bez nadzoru.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxKmF39ecDUz",
        "colab_type": "text"
      },
      "source": [
        "#Eksploracyjna analiza danych\n",
        "Nasze dane składają się z tej samej liczby danych o wydźwięku pozytywnym i negatywnym. Są to recenzje filmowe, którym przyporządkowana jest ocena od 1 do 10. W naszym zbiorze pominięte zostały recenzje ocenione na 5, ponieważ ciężko jest zdecydować, czy wówczas jest to ocena negatywna czy pozytywna. \n",
        "\n",
        "W każdym z naszych modeli słowa lub ich części zamieniane są na liczby.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK0RL9lMqHDg",
        "colab_type": "text"
      },
      "source": [
        "#Model 1\n",
        "**Opis**\n",
        "\n",
        "- Sieć, którą wykorzystujemy do uczenia naszego modelu to rekurencyjna sieć RNN (recurrent neural networks). Korzystamy z sieci rekurencyjnej, która wywołuje tę samą funkcję dla każdego wejścia danych. Wybieramy tę sieć, ponieważ może ona wykorzystywać swoją pamięć do przetwarzania sekwencji danych. Wszystkie dane wejściowe są ze sobą powiązane. \n",
        "- Architektura sieci: $ \\overrightarrow{h}^{(t)}=\\tan(h)(\\overrightarrow{a}^{(t)}) $.\n",
        "\n",
        "\n",
        "![alt text](http://dprogrammer.org/wp-content/uploads/2019/04/RNN_Core2-768x491.png)\n",
        "\n",
        "-  Funkcją kosztu dla tego modelu jest funkcja `binary_crossentropy` (funkcja straty binarnej entropii krzyżowej). Opisana wzorem:\n",
        "$H_{p}(q) = -\\frac{1}{N}\\sum_{i = 1}^{N}y_{i} \\log(p(y_i))+(1-y_{i})\\log(1-p(y_{i}))$\n",
        "\n",
        "**Działanie**\n",
        "\n",
        "- Uruchomienie: Przed uruchomieniem naszego modelu zamieniamy subsłowa (części słów) na liczby. Następnie korzystając z warstwy embedding redukujemy wymiar słów z 8000 do 16-wymiarowego wektora. \n",
        "\n",
        "- Testy: Testujemy nasz model dla danych treningowych oraz dla testowych, liczymy dla tych danych funkcję straty oraz dokładność, które prezentujemy na wykresach. \n",
        "\n",
        "- Wyniki: Dla tego modelu po uczeniu dla liczby epok 5 otrzymujemy dokładność 0.86 i wartość funkcji straty 0.47, zatem model przewiduje z wysoką dokładnością.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3Ehvl1-2RuH",
        "colab_type": "text"
      },
      "source": [
        "#Model 2\n",
        "**Opis**\n",
        "\n",
        "- Sieć, którą wykorzystujemy do uczenia naszego modelu to sieć LSTM (long short-term memory). Jest ona zmodyfikowaną wersją sieci RNN, może ona przetwarzać bardzo długie sekwencje w przeciwieństwie do RNN. Trenuje model przy użyciu propagacji wstecznej.\n",
        "- Architektura sieci: $ \\overrightarrow{h}^{(t)}=\\overrightarrow{p}^{(t)} \\tan(h)(\\overrightarrow{c}^{(h)}) $.\n",
        "\n",
        "![alt text](http://dprogrammer.org/wp-content/uploads/2019/04/LSTM-Core-768x466.png)\n",
        "\n",
        "- Funkcją kosztu jest funkcja `CrossEntropyLoss`. Opisana wzorem:\n",
        "  $H_{p}(q) = -\\sum_{c = 1}^{C} \\log(p(y_c))   $\n",
        "\n",
        "\n",
        "**Działanie**\n",
        "- Uruchomienie: Przed rozpoczęciem działania modelu tworzymy dwa słowniki jeden zawierający słowa i przyporządkowane im liczby oraz drugi zawierający etykiety 'neg' i 'pos' oraz liczby odpowiadające słowom. \n",
        "\n",
        "- Testy: Testujemy nasz model dla danych treningowych oraz testowych. Sprawdzamy poprawność naszego modelu przy pomocy funkcji straty oraz wyliczamy jego dokładność.\n",
        "\n",
        "- Wyniki: Dla 5 epok dokładność tego modelu jest większa niż pierwszego, wynosi ona 0.88, a funkcja straty tylko 0.12. Zatem model w tym miejscu jest dokładniejszy. Sprawdzenie i porównanie modeli dla uczenia w większej liczbie epok zajmuje zbyt dużo czasu.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB3YHAxy7Ue3",
        "colab_type": "text"
      },
      "source": [
        "#Podsumowanie\n",
        "\n",
        "Nasze modele działają poprawnie. Widzimy, że dokładność modelu zbudowanego przy pomocy sieci LSTM jest większa, jednakże jeśli zależy nam na czasie trwania uczenia wybierzemy model pierwszy. \n",
        "\n",
        "\n",
        "\n",
        "Najłatwiejsza w naszym zadaniu była ekspolracyjna analiza danych, ponieważ dane są bardzo dobrze przygotowane w ogólnodostępnych bibliotekach (tensorflow, torch). Trudnym okazało się zbudowanie modelu. Sprawdzenie działania drugiego modelu również nie było łatwym zadaniem, ponieważ uczenie trwało bardzo długo i sprawdzanie czy poprawianie naszych błędów przyniosło oczekiwany rezlutat zajmowało wiele czasu. \n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}